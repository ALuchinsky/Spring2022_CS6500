{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4193de37-de99-4542-828a-6963a6cac94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import format_number, mean, min, max, corr, stddev\n",
    "from pyspark.sql.functions import (dayofmonth, hour, dayofyear, month, year, weekofyear, format_number, date_format, asc, desc)\n",
    "from pyspark.sql.functions import explode, col, element_at, size, split\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dd610c-4f2b-493e-992c-aa1f1e5bafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a SparkSession named as \"test123\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('test_123') \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
    "    .config('spark.sql.session.timeZone', 'UTC') \\\n",
    "    .config('spark.driver.memory','8g') \\\n",
    "    .config('spark.ui.showConsoleProgress', True) \\\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df136550-0e8c-4e93-a941-8499d1a6d247",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9cfde37-1c21-4167-b587-66498fdde242",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/papers_2000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e84130-8a46-44fc-8a32-1e239a8a0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers_ = spark.read.option(\"multiLine\", True).option(\"mode\", \"PERMISSIVE\").option(\"encoding\", \"ascii\").json(\"../data/AL_papers.json\")\n",
    "#papers_ = spark.read.option(\"multiLine\", True).option(\"mode\", \"PERMISSIVE\").option(\"encoding\", \"ascii\").json(\"../data/data2/paps1.json\")\n",
    "papers_ = spark.read.option(\"multiLine\", True).option(\"mode\", \"PERMISSIVE\").option(\"encoding\", \"ascii\").json(\"../data/\"+data_path)\n",
    "papers = papers_.select(explode(col(\"hits.hits\")).alias(\"paper\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c3269c-9ef3-4316-9037-7e7296734d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50cb240-498e-47dc-a6d9-d2068966df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii_ignore(x):\n",
    "    return x.encode('ascii', 'ignore').decode('ascii')\n",
    "ascii_udf = udf(ascii_ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44d83ed-1fa6-49a1-8841-b02e0f1130fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- created: string (nullable = true)\n",
      " |-- number_of_pages: long (nullable = true)\n",
      " |-- keywords: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- schema: string (nullable = true)\n",
      " |    |    |-- source: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- num_refs: integer (nullable = false)\n",
      " |-- citation_count: long (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "short_papers = papers.select(\n",
    "    element_at(col(\"paper.metadata.titles.title\"), 1).alias(\"title\"),\n",
    "    element_at(col(\"paper.metadata.abstracts.value\"), 1).alias(\"abstract\"),\n",
    "    col(\"paper.created\"), col(\"paper.metadata.number_of_pages\"),\n",
    "    col(\"paper.metadata.keywords\"), size(\n",
    "        col(\"paper.metadata.references\")).alias(\"num_refs\"),\n",
    "    col(\"paper.metadata.citation_count\"),\n",
    "    col(\"paper.metadata.authors.full_name\").alias(\"authors\")\n",
    ").withColumn(\"title\", ascii_udf(\"title\"));\n",
    "short_papers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52605a6-e8f4-485e-a899-d20164ba8a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55426)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "short_papers.write.mode(\"overwrite\").json(\"../data/processed/\"+data_path+\"/short_papers/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
